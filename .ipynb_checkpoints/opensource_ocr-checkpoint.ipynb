{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee82940e-24bb-47b4-b630-0113d2fdcb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "W0901 17:18:23.963000 95112 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef50122-2b4c-4221-9d7a-a73d5dcb3fc6",
   "metadata": {},
   "source": [
    "# (Thai) OCR Test through tesserocr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2c1a51-d404-4d00-a431-46383c3d570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "import tesserocr\n",
    "import PyPDF2\n",
    "import Levenshtein\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import tesserocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f197f51a-17c3-42f3-aa9a-f957761c26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0409e2-a2a2-4f40-9cbe-239aee241387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Config ===\n",
    "pdf_path = \"ExampleOCR/ocr_example_1.pdf\"\n",
    "poppler_path = \"/opt/homebrew/bin\"\n",
    "tessdata_dir = \"/opt/homebrew/share/tessdata\"\n",
    "pic_dpi = 300\n",
    "max_pages = 3\n",
    "use_erosion = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e159f0-9c8c-4c35-8b01-cd02bb5b6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(pdf_path).parent\n",
    "pdf_stem = Path(pdf_path).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9f1789-7935-4cd5-a345-8bfc4d553d42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth saved to: ocr_example_1_groundtruth.txt\n"
     ]
    }
   ],
   "source": [
    "# === Extract Ground Truth ===\n",
    "ground_truth_text = []\n",
    "with open(pdf_path, \"rb\") as f:\n",
    "    reader = PyPDF2.PdfReader(f)\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        if max_pages and i >= max_pages:\n",
    "            break\n",
    "        text = page.extract_text() or \"\"\n",
    "        ground_truth_text.append(text.strip())\n",
    "\n",
    "groundtruth_output_path = output_dir / f\"{pdf_stem}_groundtruth.txt\"\n",
    "with open(groundtruth_output_path, \"w\", encoding=\"utf-8\") as gt_file:\n",
    "    for i, gt in enumerate(ground_truth_text):\n",
    "        gt_file.write(f\"\\n--- Page {i + 1} ---\\n{gt}\\n\")\n",
    "print(f\"Ground truth saved to: {groundtruth_output_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "345d6254-08e2-4588-963a-787c0c18e3bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# === Convert PDF to images ===\n",
    "pages = convert_from_path(pdf_path, dpi=pic_dpi, poppler_path=poppler_path)\n",
    "if max_pages:\n",
    "    pages = pages[:max_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c25a542-af8c-4dcd-b12f-1bb5fcf5464e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# === Image Preprocessing Function ===\n",
    "def preprocess_image(image, use_erosion=False):\n",
    "    \"\"\"\n",
    "    Preprocess a PIL image for OCR by enhancing contrast, sharpening,\n",
    "    binarizing, and optionally applying erosion.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image.Image): Input image.\n",
    "        use_erosion (bool): Whether to apply erosion filter (3x3 min pooling).\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: Processed binary image.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = image.convert('L')\n",
    "\n",
    "    # Auto-contrast enhancement\n",
    "    contrast = ImageOps.autocontrast(gray)\n",
    "\n",
    "    # Apply unsharp masking\n",
    "    sharpened = contrast.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))\n",
    "\n",
    "    # Convert to NumPy array for binarization\n",
    "    img_np = np.array(sharpened).astype(np.uint8)\n",
    "    binary = (img_np > 160).astype(np.uint8) * 255  # Manual thresholding\n",
    "\n",
    "    # Optional erosion (3x3 minimum filter)\n",
    "    if use_erosion:\n",
    "        padded = np.pad(binary, pad_width=1, mode='edge')\n",
    "        eroded = np.zeros_like(binary)\n",
    "        for i in range(eroded.shape[0]):\n",
    "            for j in range(eroded.shape[1]):\n",
    "                eroded[i, j] = np.min(padded[i:i+3, j:j+3])\n",
    "        binary = eroded\n",
    "\n",
    "    # Convert back to PIL image\n",
    "    return Image.fromarray(binary.astype(np.uint8), mode='L')\n",
    "\n",
    "\n",
    "# === Text Cleaning ===\n",
    "def remove_garbage_lines(text):\n",
    "    lines = text.splitlines()\n",
    "    return \"\\n\".join([line for line in lines if len(re.sub(r\"[^\\u0E00-\\u0E7F]\", \"\", line)) > 5])\n",
    "\n",
    "def clean_ocr_text(text):\n",
    "    text = re.sub(r\"[^\\u0E00-\\u0E7F\\s0-9a-zA-Z๐-๙.,“”()\\\"'ฯ\\-/:]\", \"\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5053754-d9c9-43ba-a49e-e257277873b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_pipeline(\n",
    "    pages, output_dir, pdf_stem, groundtruth_output_path,\n",
    "    ground_truth_text, ocr_engine=\"tesserocr\", tessdata_dir=\"\", use_erosion=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform OCR on a list of image pages using either Tesserocr or EasyOCR,\n",
    "    save the processed images and extracted text, and compute accuracy if ground truth is available.\n",
    "\n",
    "    Args:\n",
    "        pages (List[PIL.Image.Image]): List of PIL Image pages to process.\n",
    "        output_dir (Path): Directory where processed images will be saved.\n",
    "        pdf_stem (str): Base name of the PDF for output file naming.\n",
    "        groundtruth_output_path (str): Path to save the ground truth text (not used in writing, just for info).\n",
    "        ground_truth_text (List[str]): List of ground truth strings per page.\n",
    "        ocr_engine (str): OCR engine to use, either \"tesserocr\" or \"easyocr\".\n",
    "        tessdata_dir (str): Directory path to Tesseract language data files (used if ocr_engine is \"tesserocr\").\n",
    "        use_erosion (bool): Whether to apply erosion during preprocessing.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # === OCR and Save ===\n",
    "    ocr_output_path = output_dir / f\"{pdf_stem}_ocr_{ocr_engine}_output.txt\"\n",
    "    accuracy_results = []\n",
    "\n",
    "    accuracy_results = []\n",
    "    reader = easyocr.Reader(['th'], gpu=False) if ocr_engine == \"easyocr\" else None\n",
    "\n",
    "    with open(ocr_output_path, \"w\", encoding=\"utf-8\") as out:\n",
    "        if ocr_engine == \"tesserocr\":\n",
    "            with tesserocr.PyTessBaseAPI(path=tessdata_dir, lang='tha', oem=tesserocr.OEM.LSTM_ONLY) as api:\n",
    "                api.SetPageSegMode(tesserocr.PSM.AUTO)\n",
    "                for i, page in enumerate(pages):\n",
    "                    image_path = output_dir / f\"{pdf_stem}_page_{i + 1}.png\"\n",
    "                    processed = preprocess_image(page, use_erosion=use_erosion)\n",
    "                    processed.save(image_path)\n",
    "                    print(f\"Saved image: {image_path.name}\")\n",
    "\n",
    "                    api.SetImage(processed)\n",
    "                    raw_ocr = api.GetUTF8Text()\n",
    "                    ocr_text = clean_ocr_text(raw_ocr)\n",
    "                    ocr_text = remove_garbage_lines(ocr_text)\n",
    "\n",
    "                    out.write(f\"\\n--- Page {i + 1} ---\\n{ocr_text}\\n\")\n",
    "\n",
    "                    gt_text = ground_truth_text[i] if i < len(ground_truth_text) else \"\"\n",
    "                    if gt_text:\n",
    "                        similarity = Levenshtein.ratio(ocr_text, gt_text)\n",
    "                        accuracy_results.append((i + 1, similarity))\n",
    "                        print(f\"Page {i + 1} accuracy: {similarity:.2%}\")\n",
    "                    else:\n",
    "                        print(f\"⚠️ No ground truth available for page {i + 1}\")\n",
    "\n",
    "        elif ocr_engine == \"easyocr\":\n",
    "            for i, page in enumerate(pages):\n",
    "                image_path = output_dir / f\"{pdf_stem}_page_{i + 1}.png\"\n",
    "                processed = preprocess_image(page, use_erosion=use_erosion)\n",
    "                processed.save(image_path)\n",
    "                print(f\"Saved image: {image_path.name}\")\n",
    "\n",
    "                img_rgb = np.array(processed.convert(\"RGB\"), dtype=np.uint8)\n",
    "                img_bgr = np.ascontiguousarray(img_rgb[:, :, ::-1], dtype=np.uint8)\n",
    "\n",
    "                print(f\"Shape: {img_bgr.shape}, Dtype: {img_bgr.dtype}, Contiguous: {img_bgr.flags['C_CONTIGUOUS']}\")\n",
    "                _ = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)  # Ensure valid format\n",
    "\n",
    "                results = reader.readtext(img_bgr, detail=0, paragraph=True)\n",
    "                raw_ocr = \"\\n\".join(results)\n",
    "                ocr_text = clean_ocr_text(raw_ocr)\n",
    "                # ocr_text = remove_garbage_lines(ocr_text)  # Uncomment if needed\n",
    "\n",
    "                out.write(f\"\\n--- Page {i + 1} ---\\n{ocr_text}\\n\")\n",
    "\n",
    "                gt_text = ground_truth_text[i] if i < len(ground_truth_text) else \"\"\n",
    "                if gt_text:\n",
    "                    similarity = Levenshtein.ratio(ocr_text, gt_text)\n",
    "                    accuracy_results.append((i + 1, similarity))\n",
    "                    print(f\"Page {i + 1} accuracy: {similarity:.2%}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ No ground truth available for page {i + 1}\")\n",
    "\n",
    "    print(\"\\n==== OCR Summary: ====\")\n",
    "    for page_num, acc in accuracy_results:\n",
    "        print(f\"  - Page {page_num}: {acc:.2%} match\")\n",
    "    print(f\"\\nOCR output saved to: {ocr_output_path}\")\n",
    "    print(f\"Ground truth saved to: {groundtruth_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f798aff-6961-4782-a944-78f55d868bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image: ocr_example_1_page_1.png\n",
      "Page 1 accuracy: 82.67%\n",
      "Saved image: ocr_example_1_page_2.png\n",
      "Page 2 accuracy: 93.58%\n",
      "Saved image: ocr_example_1_page_3.png\n",
      "Page 3 accuracy: 94.78%\n",
      "\n",
      "==== OCR Summary: ====\n",
      "  - Page 1: 82.67% match\n",
      "  - Page 2: 93.58% match\n",
      "  - Page 3: 94.78% match\n",
      "\n",
      "OCR output saved to: ExampleOCR/ocr_example_1_ocr_tesserocr_output.txt\n",
      "Ground truth saved to: ExampleOCR/ocr_example_1_groundtruth.txt\n"
     ]
    }
   ],
   "source": [
    "ocr_engine = \"tesserocr\" \n",
    "run_ocr_pipeline(\n",
    "    pages, output_dir, pdf_stem, groundtruth_output_path,\n",
    "    ground_truth_text, ocr_engine=ocr_engine, tessdata_dir=tessdata_dir, use_erosion=use_erosion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e125a9-f91c-4fbd-87ab-1e960620fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image: ocr_example_1_page_1.png\n",
      "Shape: (3509, 2481, 3), Dtype: uint8, Contiguous: True\n"
     ]
    }
   ],
   "source": [
    "ocr_engine = \"easyocr\" \n",
    "run_ocr_pipeline(\n",
    "    pages, output_dir, pdf_stem, groundtruth_output_path,\n",
    "    ground_truth_text, ocr_engine=ocr_engine, tessdata_dir=tessdata_dir, use_erosion=use_erosion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee611bc-d928-49c7-8ba7-dc4d01e3989d",
   "metadata": {},
   "source": [
    "# Both OCR result combined through Gemini Flash 2.5\n",
    "หน้า ๑๑\n",
    "เล่ม ๑๓๔ ตอนที่ ๒๔ ก.\n",
    "ราชกิจจานุเบกษา\n",
    "๒๔ กุมภาพันธ์ ๒๕๖๐\n",
    "\n",
    "พระราชบัญญัติ\n",
    "การจัดซื้อจัดจ้างและการบริหารพัสดุภาครัฐ พ.ศ. ๒๕๖๐\n",
    "\n",
    "สมเด็จพระเจ้าอยู่หัวมหาวชิราลงกรณ บดินทรเทพยวรางกูร ให้ไว้ ณ วันที่ ๒๔ กุมภาพันธ์ พ.ศ. ๒๕๖๐ เป็นปีที่ ๒ ในรัชกาลปัจจุบัน\n",
    "\n",
    "สมเด็จพระเจ้าอยู่หัวมหาวชิราลงกรณ บดินทรเทพยวรางกูร มีพระราชโองการโปรดเกล้าฯ ให้ประกาศว่า โดยที่เป็นการสมควรมีกฎหมายว่าด้วยการจัดซื้อจัดจ้างและการบริหารพัสดุภาครัฐ จึงทรงพระกรุณาโปรดเกล้าฯ ให้ตราพระราชบัญญัติขึ้นไว้โดยคำแนะนำและยินยอมของ สภานิติบัญญัติแห่งชาติ ดังต่อไปนี้\n",
    "\n",
    "มาตรา ๑ พระราชบัญญัตินี้เรียกว่า “พระราชบัญญัติการจัดซื้อจัดจ้างและการบริหารพัสดุภาครัฐ พ.ศ. ๒๕๖๐”\n",
    "\n",
    "มาตรา ๒ พระราชบัญญัตินี้ให้ใช้บังคับเมื่อพ้นกำหนดหนึ่งร้อยแปดสิบวันนับแต่วันประกาศในราชกิจจานุเบกษาเป็นต้นไป\n",
    "\n",
    "มาตรา ๓ ให้ยกเลิกบทบัญญัติเกี่ยวกับพัสดุ การจัดซื้อจัดจ้าง หรือการบริหารพัสดุ ในกฎหมาย ระเบียบ ข้อบังคับ ประกาศ ข้อบัญญัติ และข้อกำหนดใด ๆ ของหน่วยงานของรัฐที่อยู่ภายใต้บังคับแห่งพระราชบัญญัตินี้\n",
    "\n",
    "มาตรา ๔ ในพระราชบัญญัตินี้ “การจัดซื้อจัดจ้าง” หมายความว่า การดำเนินการเพื่อให้ได้มาซึ่งพัสดุโดยการซื้อ จ้าง เช่า แลกเปลี่ยน หรือโดยนิติกรรมอื่นตามที่กำหนดในกฎกระทรวง\n",
    "\n",
    "“พัสดุ” หมายความว่า สินค้า งานบริการ งานก่อสร้าง งานจ้างที่ปรึกษาและงานจ้างออกแบบ หรือควบคุมงานก่อสร้าง รวมทั้งการดำเนินการอื่นตามที่กำหนดในกฎกระทรวง"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecbe186-155b-41e4-a78c-87fe5228fc95",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ce3cb-ad1a-4e6b-beba-fabe7d1ba053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdf687-8f5e-4fce-b868-edfb060c3f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_env)",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
