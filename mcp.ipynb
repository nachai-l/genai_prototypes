{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29171553-de36-4896-8473-ec7a90a31013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, asyncio, json\n",
    "from pathlib import Path\n",
    "from contextlib import AsyncExitStack\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from mcp.server.fastmcp import FastMCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f540c-6ed5-4e11-9b11-c62510743326",
   "metadata": {},
   "source": [
    "# >> MCP tools test in (mcp_multitool.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20cd4bc-bc71-44fd-9d09-77702013a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_PATH = Path(\"mcp_multitool.py\").resolve()\n",
    "assert SERVER_PATH.exists(), f\"Server script not found: {SERVER_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e837f97-d2e5-4caf-a2bb-e1b0a4f7aab9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools discovered: ['calc', 'query_sqlite', 'get_weather']\n",
      "calc add: [TextContent(type='text', text='10.0', annotations=None, meta=None)]\n",
      "calc sub: [TextContent(type='text', text='-4.0', annotations=None, meta=None)]\n",
      "SQL MCP test: [TextContent(type='text', text='{\\n  \"id\": 3,\\n  \"name\": \"Ken\",\\n  \"city\": \"Osaka\",\\n  \"spend\": 1520.75\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 1,\\n  \"name\": \"Akira\",\\n  \"city\": \"Tokyo\",\\n  \"spend\": 1200.5\\n}', annotations=None, meta=None)]\n",
      "Weather Kyoto: [TextContent(type='text', text='Kyoto: ‚òÄÔ∏è   +35¬∞C\\n', annotations=None, meta=None)]\n",
      "Weather Bangkok: [TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\n', annotations=None, meta=None)]\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    \"\"\"\n",
    "    Launch an MCP server as a subprocess (using stdio), establish a client session,\n",
    "    and demonstrate calling several registered tools.\n",
    "\n",
    "    Flow:\n",
    "    1. Configure server parameters (same Python interpreter, unbuffered output).\n",
    "    2. Launch the MCP server process and connect via stdio.\n",
    "    3. Initialize the client session and list available tools.\n",
    "    4. Call several tools (\"calc\", \"query_sqlite\", \"get_weather\") with sample arguments.\n",
    "    5. Print results to the notebook output for quick verification.\n",
    "\n",
    "    Note:\n",
    "    - In Jupyter, run with `await main()` (do not wrap in `asyncio.run`).\n",
    "    - Adjust SERVER_PATH to point to your MCP server script (e.g., mcp_multitool.py).\n",
    "    \"\"\"\n",
    "\n",
    "    async with AsyncExitStack() as stack:\n",
    "        # --- Configure MCP server process ---\n",
    "        # Use the same Python executable as the notebook kernel to ensure environment consistency\n",
    "        params = StdioServerParameters(\n",
    "            command=sys.executable,\n",
    "            args=[\"-u\", str(SERVER_PATH)],     # \"-u\" ensures unbuffered output (safer for pipes)\n",
    "            cwd=str(SERVER_PATH.parent),       # set working directory to server script's folder\n",
    "            env={                              # inherit environment + enforce unbuffered mode\n",
    "                **os.environ,\n",
    "                \"PYTHONUNBUFFERED\": \"1\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # --- Launch server and connect via stdio ---\n",
    "        # r = reader, w = writer streams for communication\n",
    "        r, w = await stack.enter_async_context(stdio_client(params))\n",
    "\n",
    "        # Create client session over the stdio pipes\n",
    "        session = await stack.enter_async_context(ClientSession(r, w))\n",
    "\n",
    "        # Initialize handshake with server (exchange capabilities, tool list, etc.)\n",
    "        await session.initialize()\n",
    "\n",
    "        # --- Tool Discovery ---\n",
    "        tools = (await session.list_tools()).tools\n",
    "        print(\"Tools discovered:\", [t.name for t in tools])\n",
    "\n",
    "        #####################\n",
    "        # Tool Testing\n",
    "        #####################\n",
    "\n",
    "        # Example 1: Basic addition\n",
    "        res = await session.call_tool(\"calc\", {\"op\": \"add\", \"a\": 3, \"b\": 7})\n",
    "        print(\"calc add:\", res.content)\n",
    "\n",
    "        # Example 2: Basic subtraction\n",
    "        res = await session.call_tool(\"calc\", {\"op\": \"sub\", \"a\": 3, \"b\": 7})\n",
    "        print(\"calc sub:\", res.content)\n",
    "\n",
    "        # Example 3: Query SQLite demo database (top spenders, limit=2)\n",
    "        res = await session.call_tool(\"query_sqlite\", {\"sql\": \"top_spenders\", \"limit\": 2})\n",
    "        print(\"SQL MCP test:\", res.content)\n",
    "\n",
    "        # Example 4: Call weather API tool for Kyoto\n",
    "        res = await session.call_tool(\"get_weather\", {\"city\": \"Kyoto\"})\n",
    "        print(\"Weather Kyoto:\", res.content)\n",
    "\n",
    "        # Example 5: Call weather API tool for Bangkok\n",
    "        res = await session.call_tool(\"get_weather\", {\"city\": \"Bangkok\"})\n",
    "        print(\"Weather Bangkok:\", res.content)\n",
    "\n",
    "# üëâ In Jupyter, use top-level await (not asyncio.run)\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335543d-0229-4960-9f7a-a42e2f182145",
   "metadata": {},
   "source": [
    "# Helper MCP functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a50cc013-52d9-4109-89e8-e54ac7a7d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, asyncio\n",
    "from contextlib import AsyncExitStack\n",
    "import google.genai as genai\n",
    "from google.genai import types\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d87cbf-7e59-48a2-ad66-aa6faa769c15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_decision(txt: str):\n",
    "    \"\"\"\n",
    "    Attempt to parse a model response string into a JSON decision dict.\n",
    "\n",
    "    Expected output from the model:\n",
    "        {\"action\": \"tool_call\", \"tool\": \"<tool_name>\", \"args\": {...}}\n",
    "    or\n",
    "        {\"action\": \"say\", \"text\": \"<final answer>\"}\n",
    "\n",
    "    If JSON parsing fails (malformed or plain text),\n",
    "    return a fallback dict with action \"say\" and the raw text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(txt.strip())\n",
    "    except Exception:\n",
    "        # fallback: treat the whole text as a final \"say\" answer\n",
    "        return {\"action\": \"say\", \"text\": txt.strip()}\n",
    "\n",
    "def mcp_content_to_plain(tool_response):\n",
    "    \"\"\"\n",
    "    Convert an MCP ToolResponse object into plain Python values.\n",
    "\n",
    "    ToolResponse.content is a list of parts (e.g., TextContent, JsonContent).\n",
    "    This function normalizes those into dicts, lists, or strings.\n",
    "\n",
    "    - If .json exists (and is data, not a method), append it.\n",
    "    - If .text exists, try parsing as JSON if it looks like JSON;\n",
    "      otherwise keep as raw string.\n",
    "    - Returns a single value if only one part, else a list of values.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for part in getattr(tool_response, \"content\", []):\n",
    "        if hasattr(part, \"json\"):\n",
    "            # some MCP parts carry structured JSON payloads\n",
    "            out.append(part.json)\n",
    "            continue\n",
    "        if hasattr(part, \"text\"):\n",
    "            t = part.text\n",
    "            # try parsing JSON if string starts with '{' or '['\n",
    "            if isinstance(t, str) and t[:1] in (\"[\", \"{\"):\n",
    "                try:\n",
    "                    out.append(json.loads(t))\n",
    "                    continue\n",
    "                except Exception:\n",
    "                    pass\n",
    "            out.append(t)\n",
    "            continue\n",
    "    return out[0] if len(out) == 1 else out\n",
    "\n",
    "def C(role: str, text: str) -> types.Content:\n",
    "    \"\"\"\n",
    "    Convenience helper to build a google.genai.types.Content message.\n",
    "\n",
    "    Args:\n",
    "        role: must be \"user\" or \"model\" in google-genai 1.32.0\n",
    "        text: plain text string to wrap\n",
    "\n",
    "    Returns:\n",
    "        types.Content object with one text part.\n",
    "    \"\"\"\n",
    "    return types.Content(role=role, parts=[types.Part(text=text)])\n",
    "\n",
    "def safe_for_json(obj):\n",
    "    \"\"\"\n",
    "    Recursively convert arbitrary Python objects into JSON-serializable form.\n",
    "\n",
    "    - Primitives (str, int, float, bool, None) are returned unchanged.\n",
    "    - dict ‚Üí recursively sanitize keys/values.\n",
    "    - list/tuple ‚Üí recursively sanitize elements.\n",
    "    - other types ‚Üí convert to string as a fallback.\n",
    "\n",
    "    Useful for cleaning MCP tool outputs before passing into json.dumps().\n",
    "    \"\"\"\n",
    "    if obj is None or isinstance(obj, (str, int, float, bool)):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): safe_for_json(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [safe_for_json(x) for x in obj]\n",
    "    # fallback: best-effort string representation\n",
    "    return str(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c271f-ac68-41a4-948b-0bafc76aef82",
   "metadata": {},
   "source": [
    "# >> Basic MCP call (max tool call: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fee5cf-052c-4a83-b18c-e4c364095af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENAI_MODEL = \"gemini-2.5-flash\"\n",
    "API_KEY     = \"AIzaSyDHOSjzr-AedFPftuIK7iiZ0yTqaTkSDYQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb81e61-2bd0-4090-a85f-e87700b86e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call_counter = 0\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "ALLOWED_TOOLS = {\"get_weather\", \"calc\", \"query_sqlite\"}\n",
    "\n",
    "SYSTEM_INSTRUCTIONS = \"\"\"You are a helpful assistant that can request a tool call.\n",
    "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
    "When a tool is useful, reply exactly:\n",
    "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
    "Valid tools:\n",
    "- get_weather(city: string)\n",
    "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
    "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
    "If no tool is needed, reply exactly:\n",
    "{\"action\":\"say\",\"text\":\"<final answer>\"}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c05f39f3-a3ae-4a03-8b76-177f9d1704fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "async def run_once(user_prompt: str):\n",
    "    \"\"\"\n",
    "    Handle a single end-to-end interaction with the LLM + MCP tool server.\n",
    "\n",
    "    Flow:\n",
    "    1. Start the MCP server subprocess (using stdio transport).\n",
    "    2. Ask the model (planner prompt) whether to call a tool or respond directly.\n",
    "    3. If a tool call is requested:\n",
    "        - Call the tool via the MCP session.\n",
    "        - Log and sanitize the result.\n",
    "        - Construct an answer prompt that includes the tool call + result.\n",
    "        - Ask the model again to produce a final natural language answer.\n",
    "    4. Return the final answer text to the caller.\n",
    "\n",
    "    Args:\n",
    "        user_prompt (str): The original user query (e.g., \"What is the weather in Kyoto today?\").\n",
    "\n",
    "    Returns:\n",
    "        str: The model's final answer text (or the raw tool payload if no text was produced).\n",
    "    \"\"\"\n",
    "    global tool_call_counter\n",
    "\n",
    "    async with AsyncExitStack() as stack:\n",
    "        # --- Start MCP server subprocess ---\n",
    "        # Launch mcp_multitool.py using the same Python interpreter as this notebook.\n",
    "        params = StdioServerParameters(\n",
    "            command=sys.executable,\n",
    "            args=[\"-u\", \"mcp_multitool.py\"],   # \"-u\" = unbuffered output (needed for stdio transport)\n",
    "            cwd=os.getcwd(),                   # set working directory to current folder\n",
    "            env=os.environ.copy(),             # inherit environment\n",
    "        )\n",
    "        # Open stdio client streams (r=reader, w=writer)\n",
    "        r, w = await stack.enter_async_context(stdio_client(params))\n",
    "        # Create client session bound to these streams\n",
    "        session = await stack.enter_async_context(ClientSession(r, w))\n",
    "        # Perform initialization handshake with the MCP server\n",
    "        await session.initialize()\n",
    "\n",
    "        # --- Turn 1: Ask the LLM for a plan (tool call vs direct answer) ---\n",
    "        planner_prompt = (\n",
    "            SYSTEM_INSTRUCTIONS\n",
    "            + \"\\n\\nUSER QUESTION:\\n\"\n",
    "            + user_prompt\n",
    "            + \"\\n\\nRespond with JSON ONLY as specified above.\"\n",
    "        )\n",
    "        print(\"\\n[Planner Prompt]\")\n",
    "        print(planner_prompt)\n",
    "        print(\"---------------------------------------------\")\n",
    "\n",
    "        # Send the planning request to the LLM\n",
    "        first = client.models.generate_content(\n",
    "            model=GENAI_MODEL,\n",
    "            contents=[C(\"user\", planner_prompt)],\n",
    "        )\n",
    "\n",
    "        # Try to parse model output into a JSON decision\n",
    "        plan = parse_decision(first.text or \"\")\n",
    "        if plan.get(\"action\") != \"tool_call\":\n",
    "            # If no tool call is requested, return model's text answer directly\n",
    "            print(f\"[No tool call] Plan: {plan}\")\n",
    "            return plan.get(\"text\", \"\")\n",
    "\n",
    "        # Extract tool name and args from the plan\n",
    "        tool_name = plan.get(\"tool\", \"\")\n",
    "        if tool_name not in ALLOWED_TOOLS:\n",
    "            return f\"Unknown/blocked tool: {tool_name}\"\n",
    "        args = plan.get(\"args\", {})\n",
    "\n",
    "        # --- Execute MCP tool call ---\n",
    "        tool_call_counter += 1\n",
    "        print(f\"\\n[Tool Call #{tool_call_counter}] {tool_name} with args={args}\")\n",
    "        print(\"---------------------------------------------\")\n",
    "\n",
    "        # Call the tool via the MCP session\n",
    "        tool_res = await session.call_tool(tool_name, args)\n",
    "        tool_payload = mcp_content_to_plain(tool_res)  # normalize ToolResponse into plain data\n",
    "        print(f\"tool_payload: {tool_payload}\")\n",
    "\n",
    "        # Sanitize for JSON dumping (avoid non-serializable objects)\n",
    "        tool_payload_safe = safe_for_json(tool_payload)\n",
    "        print(f\"tool_payload_safe: {tool_payload_safe}\")\n",
    "\n",
    "        # --- Turn 2: Ask LLM to produce a final answer given tool results ---\n",
    "        answer_prompt = (\n",
    "            f\"USER QUESTION:\\n{user_prompt}\\n\\n\"\n",
    "            f\"TOOL CALLED: {tool_name}\\n\"\n",
    "            f\"TOOL ARGS: {json.dumps(args, ensure_ascii=False)}\\n\"\n",
    "            f\"TOOL RESULT JSON (or text):\\n{json.dumps(tool_payload_safe, ensure_ascii=False)}\\n\\n\"\n",
    "            \"Please produce a concise final answer for the user using the tool result.\"\n",
    "        )\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(\"\\n[Answer Prompt]\")\n",
    "        print(answer_prompt)\n",
    "\n",
    "        # Send the follow-up to the LLM\n",
    "        follow = client.models.generate_content(\n",
    "            model=GENAI_MODEL,\n",
    "            contents=[C(\"user\", answer_prompt)],\n",
    "        )\n",
    "        print(\"=============================================\")\n",
    "\n",
    "        # Return model's natural language answer (or fallback to tool payload)\n",
    "        return follow.text or str(tool_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336e924-627e-4645-8898-57d171d95960",
   "metadata": {},
   "source": [
    "### [LV0] - Require no tool call\n",
    "[‚úì] Output - Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "561997e9-cb53-437b-9bb5-dfed02397645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32.0\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request a tool call.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "What tools are avaible?\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[No tool call] Plan: {'action': 'say', 'text': 'The available tools are: get_weather, calc, and query_sqlite.'}\n",
      "Final Result: The available tools are: get_weather, calc, and query_sqlite.\n"
     ]
    }
   ],
   "source": [
    "print(genai.__version__)\n",
    "result = await run_once(\"What tools are avaible?\")\n",
    "print(f\"Final Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48366d-ad93-4382-9398-dd63c5046167",
   "metadata": {},
   "source": [
    "### [LV1] - Require a tool to be called, only once\n",
    "[‚úì] Output - Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75760ab-a3c7-4a21-adb5-03c62134cff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32.0\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request a tool call.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "What is the weather in Bangkok today?\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #1] get_weather with args={'city': 'Bangkok'}\n",
      "---------------------------------------------\n",
      "tool_payload: <bound method BaseModel.json of TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\n', annotations=None, meta=None)>\n",
      "tool_payload_safe: <bound method BaseModel.json of TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\n', annotations=None, meta=None)>\n",
      "---------------------------------------------\n",
      "\n",
      "[Answer Prompt]\n",
      "USER QUESTION:\n",
      "What is the weather in Bangkok today?\n",
      "\n",
      "TOOL CALLED: get_weather\n",
      "TOOL ARGS: {\"city\": \"Bangkok\"}\n",
      "TOOL RESULT JSON (or text):\n",
      "\"<bound method BaseModel.json of TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\\\n', annotations=None, meta=None)>\"\n",
      "\n",
      "Please produce a concise final answer for the user using the tool result.\n",
      "=============================================\n",
      "Final Result: The weather in Bangkok is partly cloudy with a temperature of +27¬∞C.\n"
     ]
    }
   ],
   "source": [
    "print(genai.__version__)\n",
    "result = await run_once(\"What is the weather in Bangkok today?\")\n",
    "print(f\"Final Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4d695-4c98-4cb2-8e0a-422a6baaa883",
   "metadata": {},
   "source": [
    "### [LV2] - Require a tool to be called, multiple times\n",
    "[‚úó] Output - Wrong but don't hallucinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2023fd5-8e5c-420a-a3d8-7473f7a6ff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32.0\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request a tool call.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "What is the weather in Bangkok and Kyoto today?\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #2] get_weather with args={'city': 'Bangkok'}\n",
      "---------------------------------------------\n",
      "tool_payload: <bound method BaseModel.json of TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\n', annotations=None, meta=None)>\n",
      "tool_payload_safe: <bound method BaseModel.json of TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\n', annotations=None, meta=None)>\n",
      "---------------------------------------------\n",
      "\n",
      "[Answer Prompt]\n",
      "USER QUESTION:\n",
      "What is the weather in Bangkok and Kyoto today?\n",
      "\n",
      "TOOL CALLED: get_weather\n",
      "TOOL ARGS: {\"city\": \"Bangkok\"}\n",
      "TOOL RESULT JSON (or text):\n",
      "\"<bound method BaseModel.json of TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\\\n', annotations=None, meta=None)>\"\n",
      "\n",
      "Please produce a concise final answer for the user using the tool result.\n",
      "=============================================\n",
      "Final Result: Bangkok: ‚õÖÔ∏è +27¬∞C. I don't have the weather information for Kyoto.\n"
     ]
    }
   ],
   "source": [
    "print(genai.__version__)\n",
    "result = await run_once(\"What is the weather in Bangkok and Kyoto today?\")\n",
    "print(f\"Final Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a7c2c0-bfd7-4343-8820-fcbca240b34a",
   "metadata": {},
   "source": [
    "### [LV1] - Require a tool to be called, only once\n",
    "[‚úì] Output - Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39fc5f90-4c75-4e61-bec3-a02898a2fffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32.0\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request a tool call.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "Who are the two top spenders?\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[No tool call] Plan: {'action': 'say', 'text': '```json\\n{\"action\":\"tool_call\",\"tool\":\"query_sqlite\",\"args\":{\"sql\":\"top_spenders\",\"limit\":2}}\\n```'}\n",
      "Final Result: ```json\n",
      "{\"action\":\"tool_call\",\"tool\":\"query_sqlite\",\"args\":{\"sql\":\"top_spenders\",\"limit\":2}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(genai.__version__)\n",
    "result = await run_once(\"Who are the two top spenders?\")\n",
    "print(f\"Final Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb2850-08bd-4c8a-b4f9-17ee40554e83",
   "metadata": {},
   "source": [
    "### [LV1] - Require a tool to be called, only once\n",
    "[‚úì] Output - Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d85dae7a-4552-4e89-ad83-66f6343ebc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32.0\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request a tool call.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "What is 5+4+1?\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #3] calc with args={'op': 'add', 'a': 5, 'b': 4}\n",
      "---------------------------------------------\n",
      "tool_payload: <bound method BaseModel.json of TextContent(type='text', text='9.0', annotations=None, meta=None)>\n",
      "tool_payload_safe: <bound method BaseModel.json of TextContent(type='text', text='9.0', annotations=None, meta=None)>\n",
      "---------------------------------------------\n",
      "\n",
      "[Answer Prompt]\n",
      "USER QUESTION:\n",
      "What is 5+4+1?\n",
      "\n",
      "TOOL CALLED: calc\n",
      "TOOL ARGS: {\"op\": \"add\", \"a\": 5, \"b\": 4}\n",
      "TOOL RESULT JSON (or text):\n",
      "\"<bound method BaseModel.json of TextContent(type='text', text='9.0', annotations=None, meta=None)>\"\n",
      "\n",
      "Please produce a concise final answer for the user using the tool result.\n",
      "=============================================\n",
      "Final Result: 5 + 4 + 1 = 10\n"
     ]
    }
   ],
   "source": [
    "print(genai.__version__)\n",
    "result = await run_once(\"What is 5+4+1?\")\n",
    "print(f\"Final Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdc382-13d8-4e52-a99f-ff9d8b502372",
   "metadata": {},
   "source": [
    "# >> Advance MCP call (multiple tool calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4860d9e4-bfcf-487a-aa5a-845046b011ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_TOOLS = {\"get_weather\", \"calc\", \"query_sqlite\"}\n",
    "MAX_TOOL_CALLS = 5  # safety cap to avoid infinite loops\n",
    "\n",
    "SYSTEM_INSTRUCTIONS = \"\"\"You are a helpful assistant that can request one tool call at a time.\n",
    "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
    "When a tool is useful, reply exactly:\n",
    "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
    "Valid tools:\n",
    "- get_weather(city: string)\n",
    "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
    "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
    "If no tool is needed, reply exactly:\n",
    "{\"action\":\"say\",\"text\":\"<final answer>\"}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3193e6a-2820-45bd-a140-e65518d4a8bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "async def run_multiple(user_prompt: str, MAX_TOOL_CALLS=5):\n",
    "    \"\"\"\n",
    "    Handle a multi-step user query that may require multiple tool calls.\n",
    "\n",
    "    Flow:\n",
    "    1. Start the MCP server subprocess (via stdio).\n",
    "    2. Enter a planning/execution loop:\n",
    "       - Send the user question (plus transcript of prior tool calls) to the model.\n",
    "       - Parse the model's JSON response into an \"action\".\n",
    "       - If \"tool_call\":\n",
    "           * Execute the requested tool via MCP.\n",
    "           * Log the tool name, args, and results.\n",
    "           * Append results to transcript and continue loop.\n",
    "       - If \"say\":\n",
    "           * Stop planning and return the provided text as the final answer.\n",
    "    3. If loop ends without explicit text, summarize all tool results back to the\n",
    "       model to generate a concise final answer.\n",
    "    4. Return the final answer string.\n",
    "\n",
    "    Args:\n",
    "        user_prompt (str): Original user query (e.g., \"What is the weather in Bangkok and Kyoto today?\")\n",
    "        MAX_TOOL_CALLS (int): Safety cap on how many tool calls are allowed in one run.\n",
    "\n",
    "    Returns:\n",
    "        str: Final answer from the model (or \"(no answer)\" if nothing was produced).\n",
    "    \"\"\"\n",
    "    tool_calls_log = []   # Keeps a history of all tool calls executed\n",
    "    calls_made = 0        # Counter for how many tools have been called\n",
    "\n",
    "    async with AsyncExitStack() as stack:\n",
    "        # --- Start MCP server subprocess (ensure mcp_multitool.py exists in CWD) ---\n",
    "        params = StdioServerParameters(\n",
    "            command=sys.executable,\n",
    "            args=[\"-u\", \"mcp_multitool.py\"],   # \"-u\" = unbuffered output for stdio transport\n",
    "            cwd=os.getcwd(),\n",
    "            env=os.environ.copy(),\n",
    "        )\n",
    "        # Open stdio connection to the MCP server\n",
    "        r, w = await stack.enter_async_context(stdio_client(params))\n",
    "        # Create a client session bound to the stdio pipes\n",
    "        session = await stack.enter_async_context(ClientSession(r, w))\n",
    "        # Perform initialization handshake (capabilities, tool registration, etc.)\n",
    "        await session.initialize()\n",
    "\n",
    "        # --- PLAN-EXECUTE LOOP ---\n",
    "        while calls_made < MAX_TOOL_CALLS:\n",
    "            transcript = \"\"\n",
    "            if tool_calls_log:\n",
    "                # If we‚Äôve already called tools, add transcript so the model knows history\n",
    "                transcript = \"\\n\\nPREVIOUS TOOL CALLS:\\n\" + \"\\n\".join(\n",
    "                    f\"- {i+1}. {c['name']} args={json.dumps(c['args'], ensure_ascii=False)} \"\n",
    "                    f\"‚Üí result={safe_for_json(c['result'])}\"\n",
    "                    for i, c in enumerate(tool_calls_log)\n",
    "                )\n",
    "\n",
    "            # Build planner prompt = system instructions + user question + transcript\n",
    "            planner_prompt = (\n",
    "                SYSTEM_INSTRUCTIONS\n",
    "                + \"\\n\\nUSER QUESTION:\\n\"\n",
    "                + user_prompt\n",
    "                + transcript\n",
    "                + \"\\n\\nRespond with JSON ONLY as specified above.\"\n",
    "            )\n",
    "\n",
    "            # Debug: show what‚Äôs sent to model\n",
    "            print(\"\\n[Planner Prompt]\")\n",
    "            print(planner_prompt)\n",
    "            print(\"---------------------------------------------\")\n",
    "\n",
    "            # Ask the model what to do next\n",
    "            first = client.models.generate_content(\n",
    "                model=GENAI_MODEL,\n",
    "                contents=[C(\"user\", planner_prompt)],\n",
    "            )\n",
    "            # Parse JSON action (tool_call or say)\n",
    "            plan = parse_decision(first.text or \"\")\n",
    "            print(\"[Planner Raw]:\", first.text)\n",
    "            print(\"---------------------------------------------\")\n",
    "\n",
    "            if plan.get(\"action\") != \"tool_call\":\n",
    "                # If no tool call, either use text directly or finalize later\n",
    "                final_text = plan.get(\"text\", \"\")\n",
    "                if final_text:\n",
    "                    print(f\"\\n[No more tools] Final text provided by planner.\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"\\n[No more tools] Planner returned no text; will finalize with follow-up.\")\n",
    "                    break\n",
    "\n",
    "            # Extract tool call details\n",
    "            tool_name = plan.get(\"tool\", \"\")\n",
    "            if tool_name not in ALLOWED_TOOLS:\n",
    "                return f\"Unknown/blocked tool: {tool_name}\"\n",
    "            args = plan.get(\"args\", {}) or {}\n",
    "\n",
    "            calls_made += 1\n",
    "            # Debug: log which tool is being executed\n",
    "            print(f\"\\n[Tool Call #{calls_made}] {tool_name} with args={args}\")\n",
    "            print(\"---------------------------------------------\")\n",
    "\n",
    "            # Execute tool via MCP session\n",
    "            tool_res = await session.call_tool(tool_name, args)\n",
    "            tool_payload = mcp_content_to_plain(tool_res)\n",
    "            # Append to log for later transcript/finalization\n",
    "            tool_calls_log.append({\"name\": tool_name, \"args\": args, \"result\": tool_payload})\n",
    "\n",
    "            # Loop continues: planner will see updated transcript and decide again.\n",
    "\n",
    "        # --- Finalization Step ---\n",
    "        if plan.get(\"action\") == \"say\" and plan.get(\"text\"):\n",
    "            # Use text provided by planner directly\n",
    "            final_answer = plan[\"text\"].strip()\n",
    "        else:\n",
    "            # Summarize all tool calls back to model to generate final answer\n",
    "            summary = (\n",
    "                f\"USER QUESTION:\\n{user_prompt}\\n\\n\"\n",
    "                f\"TOTAL TOOL CALLS: {calls_made}\\n\"\n",
    "                \"TOOL TRANSCRIPT:\\n\" + \"\\n\".join(\n",
    "                    f\"- {i+1}. {c['name']} args={json.dumps(c['args'], ensure_ascii=False)} \"\n",
    "                    f\"‚Üí result={json.dumps(safe_for_json(c['result']), ensure_ascii=False)}\"\n",
    "                    for i, c in enumerate(tool_calls_log)\n",
    "                ) +\n",
    "                \"\\n\\nPlease produce a concise final answer for the user using all results.\"\n",
    "            )\n",
    "\n",
    "            # Debug: show finalization prompt\n",
    "            print(\"\\n[Finalization Prompt]\")\n",
    "            print(summary)\n",
    "\n",
    "            follow = client.models.generate_content(\n",
    "                model=GENAI_MODEL,\n",
    "                contents=[C(\"user\", summary)],\n",
    "            )\n",
    "            final_answer = (follow.text or \"\").strip()\n",
    "\n",
    "        # Debug: summary stats\n",
    "        print(f\"\\n[DEBUG] Total tool calls made: {calls_made}\")\n",
    "        print(\"=============================================\")\n",
    "\n",
    "        return final_answer or \"(no answer)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c77631-06ca-49e8-901c-2b33de39ff94",
   "metadata": {},
   "source": [
    "### [LV0] - Require no tool call\n",
    "[‚úì] Output - Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "508cc49d-d568-4c8f-8eeb-357a8a958789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32.0\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "What tools are avaible?\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"say\",\"text\":\"I have access to tools for getting weather, performing calculations, and querying a SQLite database.\"}\n",
      "---------------------------------------------\n",
      "\n",
      "[No more tools] Final text provided by planner.\n",
      "\n",
      "[DEBUG] Total tool calls made: 0\n",
      "=============================================\n",
      "Final Result: I have access to tools for getting weather, performing calculations, and querying a SQLite database.\n"
     ]
    }
   ],
   "source": [
    "print(genai.__version__)\n",
    "result = await run_multiple(\"What tools are avaible?\", MAX_TOOL_CALLS = MAX_TOOL_CALLS)\n",
    "print(f\"Final Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ff8fe-27da-4d59-a603-d46a26c61460",
   "metadata": {},
   "source": [
    "### [LV2] - Require a tool to be called, multiple times\n",
    "[‚úì] Output - Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8fecdde-6089-4e3d-aa30-ee5b99402b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32.0\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "What is the weather in Bangkok, Tokyo, and Kyoto today?\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"tool_call\",\"tool\":\"get_weather\",\"args\":{\"city\":\"Bangkok\"}}\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #1] get_weather with args={'city': 'Bangkok'}\n",
      "---------------------------------------------\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "What is the weather in Bangkok, Tokyo, and Kyoto today?\n",
      "\n",
      "PREVIOUS TOOL CALLS:\n",
      "- 1. get_weather args={\"city\": \"Bangkok\"} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\n', annotations=None, meta=None)>\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"tool_call\",\"tool\":\"get_weather\",\"args\":{\"city\":\"Tokyo\"}}\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #2] get_weather with args={'city': 'Tokyo'}\n",
      "---------------------------------------------\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "What is the weather in Bangkok, Tokyo, and Kyoto today?\n",
      "\n",
      "PREVIOUS TOOL CALLS:\n",
      "- 1. get_weather args={\"city\": \"Bangkok\"} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\n', annotations=None, meta=None)>\n",
      "- 2. get_weather args={\"city\": \"Tokyo\"} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='Tokyo: ‚õÖÔ∏è  +29¬∞C\\n', annotations=None, meta=None)>\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"tool_call\",\"tool\":\"get_weather\",\"args\":{\"city\":\"Kyoto\"}}\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #3] get_weather with args={'city': 'Kyoto'}\n",
      "---------------------------------------------\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "What is the weather in Bangkok, Tokyo, and Kyoto today?\n",
      "\n",
      "PREVIOUS TOOL CALLS:\n",
      "- 1. get_weather args={\"city\": \"Bangkok\"} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='Bangkok: ‚õÖÔ∏è  +27¬∞C\\n', annotations=None, meta=None)>\n",
      "- 2. get_weather args={\"city\": \"Tokyo\"} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='Tokyo: ‚õÖÔ∏è  +29¬∞C\\n', annotations=None, meta=None)>\n",
      "- 3. get_weather args={\"city\": \"Kyoto\"} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='Kyoto: ‚òÄÔ∏è   +35¬∞C\\n', annotations=None, meta=None)>\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"say\",\"text\":\"The weather in Bangkok is ‚õÖÔ∏è +27¬∞C, in Tokyo it is ‚õÖÔ∏è +29¬∞C, and in Kyoto it is ‚òÄÔ∏è +35¬∞C.\"}\n",
      "---------------------------------------------\n",
      "\n",
      "[No more tools] Final text provided by planner.\n",
      "\n",
      "[DEBUG] Total tool calls made: 3\n",
      "=============================================\n",
      "Final Result: The weather in Bangkok is ‚õÖÔ∏è +27¬∞C, in Tokyo it is ‚õÖÔ∏è +29¬∞C, and in Kyoto it is ‚òÄÔ∏è +35¬∞C.\n"
     ]
    }
   ],
   "source": [
    "print(genai.__version__)\n",
    "result = await run_multiple(\"What is the weather in Bangkok, Tokyo, and Kyoto today?\", MAX_TOOL_CALLS = MAX_TOOL_CALLS)\n",
    "print(f\"Final Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eee77f-aa41-4983-98b1-3e639b885672",
   "metadata": {},
   "source": [
    "### [LV3] - Require multiple different tools calls\n",
    "[‚úì] Output - Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eadd9832-18ad-4602-90a0-5095d4731493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32.0\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "Who is from Kyoto city? and what is the weather there today?\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"tool_call\",\"tool\":\"query_sqlite\",\"args\":{\"sql\":\"by_city\",\"city\":\"Kyoto\"}}\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #1] query_sqlite with args={'sql': 'by_city', 'city': 'Kyoto'}\n",
      "---------------------------------------------\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "Who is from Kyoto city? and what is the weather there today?\n",
      "\n",
      "PREVIOUS TOOL CALLS:\n",
      "- 1. query_sqlite args={\"sql\": \"by_city\", \"city\": \"Kyoto\"} ‚Üí result=['<bound method BaseModel.json of TextContent(type=\\'text\\', text=\\'{\\\\n  \"id\": 2,\\\\n  \"name\": \"Mika\",\\\\n  \"city\": \"Kyoto\",\\\\n  \"spend\": 830.0\\\\n}\\', annotations=None, meta=None)>', '<bound method BaseModel.json of TextContent(type=\\'text\\', text=\\'{\\\\n  \"id\": 4,\\\\n  \"name\": \"Aoi\",\\\\n  \"city\": \"Kyoto\",\\\\n  \"spend\": 410.1\\\\n}\\', annotations=None, meta=None)>']\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"tool_call\",\"tool\":\"get_weather\",\"args\":{\"city\":\"Kyoto\"}}\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #2] get_weather with args={'city': 'Kyoto'}\n",
      "---------------------------------------------\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "Who is from Kyoto city? and what is the weather there today?\n",
      "\n",
      "PREVIOUS TOOL CALLS:\n",
      "- 1. query_sqlite args={\"sql\": \"by_city\", \"city\": \"Kyoto\"} ‚Üí result=['<bound method BaseModel.json of TextContent(type=\\'text\\', text=\\'{\\\\n  \"id\": 2,\\\\n  \"name\": \"Mika\",\\\\n  \"city\": \"Kyoto\",\\\\n  \"spend\": 830.0\\\\n}\\', annotations=None, meta=None)>', '<bound method BaseModel.json of TextContent(type=\\'text\\', text=\\'{\\\\n  \"id\": 4,\\\\n  \"name\": \"Aoi\",\\\\n  \"city\": \"Kyoto\",\\\\n  \"spend\": 410.1\\\\n}\\', annotations=None, meta=None)>']\n",
      "- 2. get_weather args={\"city\": \"Kyoto\"} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='Kyoto: ‚òÄÔ∏è   +35¬∞C\\n', annotations=None, meta=None)>\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"say\",\"text\":\"Mika and Aoi are from Kyoto city. The weather there today is ‚òÄÔ∏è +35¬∞C.\"}\n",
      "---------------------------------------------\n",
      "\n",
      "[No more tools] Final text provided by planner.\n",
      "\n",
      "[DEBUG] Total tool calls made: 2\n",
      "=============================================\n",
      "Final Result: Mika and Aoi are from Kyoto city. The weather there today is ‚òÄÔ∏è +35¬∞C.\n"
     ]
    }
   ],
   "source": [
    "print(genai.__version__)\n",
    "result = await run_multiple(\n",
    "    \"Who is from Kyoto city? and what is the weather there today?\", \n",
    "    MAX_TOOL_CALLS = MAX_TOOL_CALLS\n",
    ")\n",
    "print(f\"Final Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c6618-5774-405b-9ea3-ddcbf1722df7",
   "metadata": {},
   "source": [
    "### [LV4] - Require complex tools calling, calling one tool multiple tims and compare the results\n",
    "[‚úó] Output - Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7a217ad-bce5-4450-87a7-c4ad7286d496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32.0\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "Who is the top 1 spender from Kyoto city? and what is the weather there today?\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"tool_call\",\"tool\":\"query_sqlite\",\"args\":{\"sql\":\"top_spenders\",\"city\":\"Kyoto\",\"limit\":1}}\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #1] query_sqlite with args={'sql': 'top_spenders', 'city': 'Kyoto', 'limit': 1}\n",
      "---------------------------------------------\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "Who is the top 1 spender from Kyoto city? and what is the weather there today?\n",
      "\n",
      "PREVIOUS TOOL CALLS:\n",
      "- 1. query_sqlite args={\"sql\": \"top_spenders\", \"city\": \"Kyoto\", \"limit\": 1} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='{\\n  \"id\": 3,\\n  \"name\": \"Ken\",\\n  \"city\": \"Osaka\",\\n  \"spend\": 1520.75\\n}', annotations=None, meta=None)>\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"tool_call\",\"tool\":\"get_weather\",\"args\":{\"city\":\"Kyoto\"}}\n",
      "---------------------------------------------\n",
      "\n",
      "[Tool Call #2] get_weather with args={'city': 'Kyoto'}\n",
      "---------------------------------------------\n",
      "\n",
      "[Planner Prompt]\n",
      "You are a helpful assistant that can request one tool call at a time.\n",
      "Return STRICT JSON only (no prose). Use double quotes for all keys/strings.\n",
      "When a tool is useful, reply exactly:\n",
      "{\"action\":\"tool_call\",\"tool\":\"<name>\",\"args\":{...}}\n",
      "Valid tools:\n",
      "- get_weather(city: string)\n",
      "- calc(op: \"add\"|\"sub\"|\"mul\"|\"div\"|\"pow\"|\"sqrt\", a: number, b?: number)\n",
      "- query_sqlite(sql: \"by_city\"|\"top_spenders\"|\"by_name_like\", city?: string, limit?: integer, name_like?: string)\n",
      "If no tool is needed, reply exactly:\n",
      "{\"action\":\"say\",\"text\":\"<final answer>\"}\n",
      "\n",
      "USER QUESTION:\n",
      "Who is the top 1 spender from Kyoto city? and what is the weather there today?\n",
      "\n",
      "PREVIOUS TOOL CALLS:\n",
      "- 1. query_sqlite args={\"sql\": \"top_spenders\", \"city\": \"Kyoto\", \"limit\": 1} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='{\\n  \"id\": 3,\\n  \"name\": \"Ken\",\\n  \"city\": \"Osaka\",\\n  \"spend\": 1520.75\\n}', annotations=None, meta=None)>\n",
      "- 2. get_weather args={\"city\": \"Kyoto\"} ‚Üí result=<bound method BaseModel.json of TextContent(type='text', text='Kyoto: ‚òÄÔ∏è   +35¬∞C\\n', annotations=None, meta=None)>\n",
      "\n",
      "Respond with JSON ONLY as specified above.\n",
      "---------------------------------------------\n",
      "[Planner Raw]: {\"action\":\"say\",\"text\":\"According to the database, the top spender found when querying for Kyoto is Ken from Osaka. The weather in Kyoto today is ‚òÄÔ∏è +35¬∞C.\"}\n",
      "---------------------------------------------\n",
      "\n",
      "[No more tools] Final text provided by planner.\n",
      "\n",
      "[DEBUG] Total tool calls made: 2\n",
      "=============================================\n",
      "Final Result: According to the database, the top spender found when querying for Kyoto is Ken from Osaka. The weather in Kyoto today is ‚òÄÔ∏è +35¬∞C.\n"
     ]
    }
   ],
   "source": [
    "print(genai.__version__)\n",
    "result = await run_multiple(\n",
    "    \"Who is the top 1 spender from Kyoto city? and what is the weather there today?\", \n",
    "    MAX_TOOL_CALLS = MAX_TOOL_CALLS\n",
    ")\n",
    "print(f\"Final Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae4632-0549-40a3-812b-ee7f9c7ceda2",
   "metadata": {},
   "source": [
    "# üîß What more can be Added (and Why)\n",
    "\n",
    "## 1. Multi-step planning (not just one step at a time)\n",
    "- Let the planner return a **plan (array of steps)** so the runtime can execute several tool calls deterministically before asking the LLM again.  \n",
    "- ‚úÖ Reduces back-and-forth tokens  \n",
    "- ‚úÖ Enables simple workflows (e.g., extract cities ‚Üí fetch weather for each ‚Üí summarize)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Parallelization where safe\n",
    "- When steps are **independent** (e.g., multiple cities), run tool calls concurrently.  \n",
    "- ‚úÖ Cuts latency and improves throughput\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Validation & guards\n",
    "- Validate tool names/args against schemas (e.g., Pydantic) before calling  \n",
    "- Retry when the planner emits non-JSON  \n",
    "- Cap tool calls, add timeouts, and abort on repeated failures  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Memory & state\n",
    "- **Episodic memory**: remember recent tool results to reference in follow-ups  \n",
    "- **Semantic memory**: cache facts (e.g., last known weather per city) and compress transcripts to avoid context bloat  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Observation compression\n",
    "- Summarize/normalize tool outputs before feeding them back to the model  \n",
    "- ‚úÖ Keeps prompts small  \n",
    "- ‚úÖ Increases signal-to-noise  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Detectors & self-checks\n",
    "- Ask the model to verify: *‚ÄúDid we cover all requested entities?‚Äù*  \n",
    "- Add simple consistency checks on results (e.g., schema/units)  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Cost/latency telemetry\n",
    "- Log per-turn timers, token estimates, and tool latency  \n",
    "- Emit structured logs (e.g., JSON) for post-hoc debugging  \n",
    "\n",
    "---\n",
    "\n",
    "## 8. Policy guardrails\n",
    "- Disallow risky tools by default  \n",
    "- Add an approval gate (*human-in-the-loop*) for destructive or irreversible actions  \n",
    "\n",
    "---\n",
    "\n",
    "## 9. Caching\n",
    "- Memoize tool outputs by `(tool_name, args)` with TTL  \n",
    "- Short-circuit repeated calls inside the same run  \n",
    "\n",
    "---\n",
    "\n",
    "## 10. Better prompting\n",
    "- Add a **‚Äúcover all entities‚Äù** rule for multi-item asks  \n",
    "- Define an **explicit plan schema** for the planner  \n",
    "- Enforce **deterministic JSON with retry** on failure  \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_env)",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
