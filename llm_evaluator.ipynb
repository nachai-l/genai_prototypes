{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3922c23b-e969-4b60-995a-7d3d291164c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from typing import Optional, Dict, Any\n",
    "import google.genai as genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcda4af2-559e-4431-9fa9-d336115d1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"AIzaSyDHOSjzr-AedFPftuIK7iiZ0yTqaTkSDYQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530a70ac-5154-42f5-82e6-9f3ec0d2a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865c4fdb-bc92-4e54-a8a5-16b220574bf7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Gemini Generate text functions\n",
    "def extract_text(r):\n",
    "    out = []\n",
    "    for c in getattr(r, \"candidates\", []) or []:\n",
    "        # finish_reason can be useful: types.FinishReason.STOP, SAFETY, etc.\n",
    "        # print(\"finish_reason:\", c.finish_reason)\n",
    "        content = getattr(c, \"content\", None)\n",
    "        if content:\n",
    "            for p in getattr(content, \"parts\", []) or []:\n",
    "                t = getattr(p, \"text\", None)\n",
    "                if t:\n",
    "                    out.append(t)\n",
    "    # Fallback to r.text if present\n",
    "    return \"\\n\".join(out) or getattr(r, \"text\", \"\") or \"\"\n",
    "    \n",
    "def generate_text(client, prompt: str, max_tokens: int = 1024, temperature: float = 0.7, verbose = 0) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Generate text using Gemini API.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input prompt for text generation\n",
    "        max_tokens (int): Maximum number of tokens to generate\n",
    "        temperature (float): Controls randomness (0.0 to 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        Optional[str]: Generated text or None if request fails\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        resp = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=[{\"role\": \"user\", \"parts\": [{\"text\": prompt}]}],\n",
    "            config=types.GenerateContentConfig(\n",
    "                max_output_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "        )\n",
    "        answer_text = extract_text(resp)\n",
    "        if verbose > 0:\n",
    "            print(f\"Answer to be Evaluation Response: {answer_text}\")\n",
    "        return answer_text, resp\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67859fd-75e2-457f-8aa7-2f2a86f5f1a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Gemini text evaluation\n",
    "def extract_score(evaluation_text: str) -> float:\n",
    "    \"\"\"\n",
    "    Extract numerical score from evaluation text.\n",
    "    \n",
    "    Args:\n",
    "        evaluation_text (str): The evaluation response text\n",
    "    \n",
    "    Returns:\n",
    "        float: Extracted score or 0.0 if extraction fails\n",
    "    \"\"\"\n",
    "    # Look for decimal numbers between 0 and 1\n",
    "    patterns = [\n",
    "        r'\\b(0\\.\\d+|1\\.0+|0\\.0+)\\b',  # Decimal format (0.75, 1.0, 0.0)\n",
    "        r'\\b([0-9](?:\\.[0-9]+)?)/10\\b',  # X/10 format\n",
    "        r'\\b(\\d+)%\\b',  # Percentage format\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, evaluation_text)\n",
    "        if matches:\n",
    "            try:\n",
    "                score_str = matches[0]\n",
    "                if '/' in score_str:\n",
    "                    # Handle X/10 format\n",
    "                    score = float(score_str.split('/')[0]) / 10.0\n",
    "                elif '%' in score_str:\n",
    "                    # Handle percentage format\n",
    "                    score = float(score_str.replace('%', '')) / 100.0\n",
    "                else:\n",
    "                    # Handle decimal format\n",
    "                    score = float(score_str)\n",
    "                \n",
    "                # Ensure score is in valid range\n",
    "                if 0.0 <= score <= 1.0:\n",
    "                    return score\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    print(f\"Could not extract score from: {evaluation_text}\")\n",
    "    return 0.0\n",
    "\n",
    "def evaluate_answer(\n",
    "    client,\n",
    "    question: str, answer: str, reference_answer: str = None,\n",
    "    system_prompt = \"\"\"\n",
    "    Please evaluate the quality of the given answer to the question on a scale of 0.0 to 1.0, where:\n",
    "    - 0.0 = Completely incorrect, irrelevant, or nonsensical\n",
    "    - 0.5 = Partially correct but missing key information or has some errors\n",
    "    - 1.0 = Excellent, accurate, and comprehensive answer\n",
    "    \n",
    "    Consider accuracy, completeness, clarity, and relevance. Respond with just the numerical score (e.g., 0.75) followed by a brief explanation.\n",
    "    If Reference answer is provided, answer according to its information only.\n",
    "    \"\"\",\n",
    "    verbose = 0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the quality of an answer using Gemini API.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The original question\n",
    "        answer (str): The answer to evaluate\n",
    "        reference_answer (str, optional): Reference answer for comparison\n",
    "    \n",
    "    Returns:\n",
    "        float: Evaluation score between 0.0 and 1.0\n",
    "    \"\"\"\n",
    "    evaluation_prompt = system_prompt + f\"/n Question: {question}\"\n",
    "    evaluation_prompt = evaluation_prompt + f\"/n Answer to evaluate: {answer}\"\n",
    "\n",
    "    # Construct evaluation prompt\n",
    "    if reference_answer:\n",
    "        evaluation_prompt = evaluation_prompt + f\"/n Reference answer: {reference_answer}\"\n",
    "    \n",
    "    # Get evaluation from Gemini\n",
    "    evaluation_response, response = generate_text(client, evaluation_prompt, max_tokens=4096, temperature=0.1)\n",
    "    if verbose > 0:\n",
    "        print(f\"Evaluation Response: {evaluation_response}\")\n",
    "    \n",
    "    if not evaluation_response:\n",
    "        print(\"Failed to get evaluation response\")\n",
    "        return -1.0\n",
    "    \n",
    "    # Extract numerical score from response\n",
    "    score = extract_score(evaluation_response)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(f\"Score: {score:.2f}\")\n",
    "    return max(0.0, min(1.0, score))  # Ensure score is between 0.0 and 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838bf19f-85b5-4577-bcb4-accaa49dfea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to be Evaluation Response: The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "verbose = 1\n",
    "question = \"What is the capital of France?\"\n",
    "reference_answer = \"The capital of France is Paris, which is also the country's largest city and cultural center.\"\n",
    "answer_text = generate_text(client, question, max_tokens = 1024, temperature = 0.7, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b37723-6411-408c-8211-b64cca9dbf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Response: 1.0\n",
      "The answer is accurate, clear, and directly answers the question. While the reference answer provides additional context (largest city and cultural center), the given answer fully addresses the specific question asked, making it excellent and comprehensive for the query.\n",
      "Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_answer(client, question, answer_text, reference_answer = reference_answer, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a32954f-cb53-456b-b97e-47674f63bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Response: 0.0\n",
      "The answer is completely incorrect. The capital of France is Paris, not Bangkok.\n",
      "Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "answer_text = \"The capital of France is **Bangkok**.\"\n",
    "score = evaluate_answer(client, question, answer_text, reference_answer = reference_answer, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb916048-43e6-40d7-9adf-4b46ae201d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Response: 0.5 The answer correctly identifies Paris as the likely capital but introduces Bangkok as a possibility, which is completely incorrect and misleading. The \"likely\" also adds an unnecessary degree of uncertainty compared to the definitive reference.\n",
      "Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "answer_text = \"The capital of France is likely **Paris** but maybe **Bangkok**.\"\n",
    "score = evaluate_answer(client, question, answer_text, reference_answer = reference_answer, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec05ce67-6520-4614-b84e-d257e7c0dd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Response: 0.0 The evaluated answer states \"Paris\" and \"Bangkok,\" neither of which matches the capital \"Mararis\" provided in the reference answer. According to the reference, the answer is completely incorrect.\n",
      "Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "reference_answer = \"The capital of France is Mararis, they just moved it here\"\n",
    "score = evaluate_answer(client, question, answer_text, reference_answer = reference_answer, verbose = verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf1a47-1968-4791-bfb6-cb069137d969",
   "metadata": {},
   "source": [
    "## Productionize Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fbbfd79-987a-4bf6-9c65-83199ce92d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import google.genai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ab3f0f2-65e0-4e1c-879a-bf225519158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import genai_functions.gemini_textgen_functions as gemini_textgen_functs\n",
    "import genai_functions.gemini_texteva_functions as gemini_texteva_functs\n",
    "import genai_functions.gemini_usage_logging as gemini_log_functs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fff18a3-bc9b-4b43-be29-89454e3dc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"AIzaSyDHOSjzr-AedFPftuIK7iiZ0yTqaTkSDYQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f6071cc-5008-4b05-9df4-6d380cfced9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"เมืองหลวงของประเทศไทยคือ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d16da44-f373-41af-8a3d-764dd7d886df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:genai_functions.gemini_textgen_functions:GeminiTextGenerator initialized with model: gemini-2.5-flash\n",
      "INFO:genai_functions.gemini_textgen_functions:Generating text with model: gemini-2.5-flash, max_tokens: 512, temperature: 0.50\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n",
      "INFO:genai_functions.gemini_usage_logging:GeminiUsageLogger initialized with 4 existing logs (persist=True)\n",
      "INFO:genai_functions.gemini_usage_logging:Added log entry: query_len=25, total_tokens=56\n",
      "INFO:genai_functions.gemini_textgen_functions:Successfully generated 51 characters of text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เมืองหลวงของประเทศไทยคือ **กรุงเทพมหานคร** ครับ/ค่ะ\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "config    = gemini_textgen_functs.GenerationConfig(max_tokens=512, temperature=0.5)\n",
    "generator = gemini_textgen_functs.GeminiTextGenerator(client, config)\n",
    "res_text, response = generator.generate_text(question)\n",
    "print(res_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b5d858e-b307-420e-a5c3-43411efbdfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:genai_functions.gemini_texteva_functions:GeminiTextEvaluator initialized\n"
     ]
    }
   ],
   "source": [
    "eva_config = gemini_texteva_functs.EvaluationConfig(temperature=0.0, max_tokens=1024)\n",
    "evaluator  = gemini_texteva_functs.GeminiTextEvaluator(client, eva_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfb7a715-d636-4cae-9ff2-ddf5e7f72222",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answer = \"Capital of Thailand is Bangkok\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d637c5f-bfb4-49e1-ac84-2971ac6dcae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:genai_functions.gemini_texteva_functions:Evaluating answer quality for question length: 25, answer length: 51\n",
      "INFO:genai_functions.gemini_texteva_functions:Evaluation prompt: \n",
      "Please evaluate the quality of the given answer to the question on a scale of 0.0 to 1.0, where:\n",
      "- 0.0 = Completely incorrect, irrelevant, or nonsensical\n",
      "- 0.5 = Partially correct but missing key information or has some errors\n",
      "- 1.0 = Excellent, accurate, and comprehensive answer\n",
      "\n",
      "Consider accuracy...\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n",
      "INFO:genai_functions.gemini_usage_logging:GeminiUsageLogger initialized with 5 existing logs (persist=True)\n",
      "INFO:genai_functions.gemini_usage_logging:Added log entry: query_len=607, total_tokens=367\n",
      "INFO:genai_functions.gemini_texteva_functions:Evaluation response: 1.0\n",
      "คำตอบถูกต้อง ครบถ้วน ชัดเจน และตรงประเด็น\n",
      "INFO:genai_functions.gemini_texteva_functions:Final evaluation score: 1.000\n",
      "INFO:genai_functions.gemini_texteva_functions:Evaluating answer quality for question length: 25, answer length: 51\n",
      "INFO:genai_functions.gemini_texteva_functions:Evaluation prompt: \n",
      "Please evaluate the quality of the given answer to the question on a scale of 0.0 to 1.0, where:\n",
      "- 0.0 = Completely incorrect, irrelevant, or nonsensical\n",
      "- 0.5 = Partially correct but missing key information or has some errors\n",
      "- 1.0 = Excellent, accurate, and comprehensive answer\n",
      "\n",
      "Consider accuracy...\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n",
      "INFO:genai_functions.gemini_usage_logging:GeminiUsageLogger initialized with 6 existing logs (persist=True)\n",
      "INFO:genai_functions.gemini_usage_logging:Added log entry: query_len=656, total_tokens=482\n",
      "INFO:genai_functions.gemini_texteva_functions:Evaluation response: 1.0\n",
      "The answer correctly identifies the capital of Thailand as \"กรุงเทพมหานคร\" (Krung Thep Maha Nakhon), which is the official name for Bangkok. It is accurate, complete, and directly answers the question. The polite particle \"ครับ/ค่ะ\" is also appropriate for a conversational response in Thai.\n",
      "INFO:genai_functions.gemini_texteva_functions:Final evaluation score: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_wo_ref: 1.0\n",
      "score_w_ref:  1.0\n"
     ]
    }
   ],
   "source": [
    "score_wo_ref = evaluator.evaluate_answer_quality(question, res_text, verbose=True)\n",
    "score_w_ref  = evaluator.evaluate_answer_quality(question, res_text, reference_answer, verbose=True)\n",
    "print(f\"score_wo_ref: {score_wo_ref}\")\n",
    "print(f\"score_w_ref:  {score_w_ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5126d53c-cfe1-4ddf-b554-d5cace31f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answer = \"Capital of Thailand is Chaing Mai, they juse moved it here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10001193-bc01-43e7-98b4-3e2857233585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:genai_functions.gemini_texteva_functions:Evaluating answer quality for question length: 25, answer length: 51\n",
      "INFO:genai_functions.gemini_texteva_functions:Evaluation prompt: \n",
      "Please evaluate the quality of the given answer to the question on a scale of 0.0 to 1.0, where:\n",
      "- 0.0 = Completely incorrect, irrelevant, or nonsensical\n",
      "- 0.5 = Partially correct but missing key information or has some errors\n",
      "- 1.0 = Excellent, accurate, and comprehensive answer\n",
      "\n",
      "Consider accuracy...\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n",
      "INFO:genai_functions.gemini_usage_logging:GeminiUsageLogger initialized with 7 existing logs (persist=True)\n",
      "INFO:genai_functions.gemini_usage_logging:Added log entry: query_len=684, total_tokens=428\n",
      "INFO:genai_functions.gemini_texteva_functions:Evaluation response: 0.0\n",
      "The reference answer explicitly states that the capital of Thailand is Chiang Mai. The answer to evaluate states that the capital is Bangkok, which directly contradicts the information provided in the reference.\n",
      "INFO:genai_functions.gemini_texteva_functions:Final evaluation score: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_w_ref: 0.0\n"
     ]
    }
   ],
   "source": [
    "score_w_ref  = evaluator.evaluate_answer_quality(question, res_text, reference_answer, verbose=True)\n",
    "print(f\"score_w_ref: {score_w_ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ead25e58-06d0-42e6-918f-590bbef13846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:genai_functions.gemini_usage_logging:GeminiUsageLogger initialized with 8 existing logs (persist=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_tokens_per_request': 166.625,\n",
      " 'date_range': (Timestamp('2025-09-08 07:22:02.188114+0000', tz='UTC'),\n",
      "                Timestamp('2025-09-08 08:41:11.159131+0000', tz='UTC')),\n",
      " 'finish_reasons': {'STOP': 4},\n",
      " 'total_requests': 8,\n",
      " 'total_tokens': 1333}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>query</th>\n",
       "      <th>uploaded_file</th>\n",
       "      <th>response_text</th>\n",
       "      <th>finish_reason</th>\n",
       "      <th>cached_content_token_count</th>\n",
       "      <th>candidates_token_count</th>\n",
       "      <th>prompt_token_count</th>\n",
       "      <th>thoughts_token_count</th>\n",
       "      <th>total_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-08 07:37:47.978513+00:00</td>\n",
       "      <td>What is RAG?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-08 08:41:05.392691+00:00</td>\n",
       "      <td>เมืองหลวงของประเทศไทยคือ?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>เมืองหลวงของประเทศไทยคือ **กรุงเทพมหานคร** ครั...</td>\n",
       "      <td>STOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09-08 08:41:07.095227+00:00</td>\n",
       "      <td>\\nPlease evaluate the quality of the given ans...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0\\nคำตอบถูกต้อง ครบถ้วน ชัดเจน และตรงประเด็น</td>\n",
       "      <td>STOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>152</td>\n",
       "      <td>196</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-09-08 08:41:09.551516+00:00</td>\n",
       "      <td>\\nPlease evaluate the quality of the given ans...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0\\nThe answer correctly identifies the capit...</td>\n",
       "      <td>STOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>161</td>\n",
       "      <td>254</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-09-08 08:41:11.159131+00:00</td>\n",
       "      <td>\\nPlease evaluate the quality of the given ans...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0\\nThe reference answer explicitly states th...</td>\n",
       "      <td>STOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>170</td>\n",
       "      <td>219</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp  \\\n",
       "3 2025-09-08 07:37:47.978513+00:00   \n",
       "4 2025-09-08 08:41:05.392691+00:00   \n",
       "5 2025-09-08 08:41:07.095227+00:00   \n",
       "6 2025-09-08 08:41:09.551516+00:00   \n",
       "7 2025-09-08 08:41:11.159131+00:00   \n",
       "\n",
       "                                               query uploaded_file  \\\n",
       "3                                       What is RAG?           NaN   \n",
       "4                          เมืองหลวงของประเทศไทยคือ?           NaN   \n",
       "5  \\nPlease evaluate the quality of the given ans...           NaN   \n",
       "6  \\nPlease evaluate the quality of the given ans...           NaN   \n",
       "7  \\nPlease evaluate the quality of the given ans...           NaN   \n",
       "\n",
       "                                       response_text finish_reason  \\\n",
       "3                                                NaN           NaN   \n",
       "4  เมืองหลวงของประเทศไทยคือ **กรุงเทพมหานคร** ครั...          STOP   \n",
       "5     1.0\\nคำตอบถูกต้อง ครบถ้วน ชัดเจน และตรงประเด็น          STOP   \n",
       "6  1.0\\nThe answer correctly identifies the capit...          STOP   \n",
       "7  0.0\\nThe reference answer explicitly states th...          STOP   \n",
       "\n",
       "  cached_content_token_count candidates_token_count prompt_token_count  \\\n",
       "3                        NaN                    NaN                NaN   \n",
       "4                        NaN                     15                  7   \n",
       "5                        NaN                     19                152   \n",
       "6                        NaN                     67                161   \n",
       "7                        NaN                     39                170   \n",
       "\n",
       "  thoughts_token_count total_token_count  \n",
       "3                  NaN               NaN  \n",
       "4                   34                56  \n",
       "5                  196               367  \n",
       "6                  254               482  \n",
       "7                  219               428  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import genai_functions.gemini_usage_logging as gemini_log_functs\n",
    "import pprint\n",
    "\n",
    "gemini_logger = gemini_log_functs.GeminiUsageLogger(log_path=\"logs/gemini_usage.csv\")\n",
    "pprint.pprint(gemini_logger.get_usage_summary())\n",
    "logs_df = gemini_logger.get_logs_dataframe()\n",
    "logs_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd366eb5-d2fc-4f56-abbd-ab3771e1b4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_env)",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
